{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7b14cd",
   "metadata": {},
   "source": [
    "\n",
    "# EDA Multivariado — Consumo de Gas (Distribución, Estacionalidad y Correlación)\n",
    "\n",
    "Cuaderno listo para ejecutar sobre **df_contugas.csv**, con:\n",
    "- Revisión de **todas las variables numéricas** (histograma, boxplot, QQ-plot, normalidad).\n",
    "- **Serie temporal**: gráfico, **ADF/KPSS**, **ACF/PACF** y **descomposición estacional** (periodo inferido).\n",
    "- **Correlación** entre numéricas.\n",
    "- **Análisis por Cliente** (opcional) para descubrir estacionalidad diaria/semanal y % de ceros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) Bootstrap de dependencias en tu entorno local.\n",
    "# Comenta esta celda si ya cuentas con estos paquetes.\n",
    "try:\n",
    "    import statsmodels, scipy  # noqa: F401\n",
    "except Exception:\n",
    "    %pip install --upgrade pip\n",
    "    %pip install statsmodels scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2241cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# Parámetros del análisis\n",
    "# ============================\n",
    "FILE_PATH = \"/mnt/data/df_contugas.csv\"  # Cambia la ruta si es necesario\n",
    "CSV_SEP = None      # None = autodetección ('engine=\"python\"'); o pon ';' / ',' / '\\t'\n",
    "CLIENTE_TOP_N = 5   # Número de clientes a analizar individualmente\n",
    "BY_CLIENT = True    # Activar análisis por cliente\n",
    "SAMPLE_FOR_PLOTS = None  # Si el dataset es muy grande, fija un número (p.ej., 200000)\n",
    "\n",
    "# ============================\n",
    "# Importaciones\n",
    "# ============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.api import qqplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 140)\n",
    "pd.set_option(\"display.width\", 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94acf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================\n",
    "# Funciones auxiliares\n",
    "# =========================================\n",
    "\n",
    "def describe_normality(x: pd.Series, alpha: float = 0.05, sample_n: int = 10000) -> dict:\n",
    "    x = x.dropna()\n",
    "    n = len(x)\n",
    "    out = {\"n\": int(n)}\n",
    "    if n == 0:\n",
    "        return out\n",
    "    xs = x.sample(min(sample_n, n), random_state=42) if n > sample_n else x\n",
    "    try:\n",
    "        W, p = stats.shapiro(xs)\n",
    "        out[\"shapiro_W\"] = float(W); out[\"shapiro_p\"] = float(p); out[\"shapiro_normal\"] = bool(p > alpha)\n",
    "    except Exception as e:\n",
    "        out[\"shapiro_error\"] = str(e)\n",
    "    try:\n",
    "        k2, p = stats.normaltest(x)\n",
    "        out[\"dagostino_K2\"] = float(k2); out[\"dagostino_p\"] = float(p); out[\"dagostino_normal\"] = bool(p > alpha)\n",
    "    except Exception as e:\n",
    "        out[\"dagostino_error\"] = str(e)\n",
    "    try:\n",
    "        jb_stat, jb_p, _, _ = jarque_bera(x)\n",
    "        out[\"jarque_bera\"] = float(jb_stat); out[\"jarque_bera_p\"] = float(jb_p); out[\"jarque_bera_normal\"] = bool(jb_p > alpha)\n",
    "    except Exception as e:\n",
    "        out[\"jarque_bera_error\"] = str(e)\n",
    "    try:\n",
    "        ad = stats.anderson(x, dist=\"norm\")\n",
    "        out[\"anderson_stat\"] = float(ad.statistic)\n",
    "        out[\"anderson_crit\"] = [float(v) for v in ad.critical_values]\n",
    "        out[\"anderson_sig\"] = [float(v) for v in ad.significance_level]\n",
    "    except Exception as e:\n",
    "        out[\"anderson_error\"] = str(e)\n",
    "    try:\n",
    "        out[\"skew\"] = float(stats.skew(x)); out[\"kurtosis\"] = float(stats.kurtosis(x, fisher=True))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "def infer_seasonal_period(series: pd.Series, max_lag: int = 400) -> Optional[int]:\n",
    "    s = series.dropna().values\n",
    "    if len(s) < 20:\n",
    "        return None\n",
    "    s = (s - np.mean(s)) / (np.std(s) if np.std(s) != 0 else 1)\n",
    "    acf_vals = [1.0]\n",
    "    L = min(max_lag, len(s) - 1)\n",
    "    for lag in range(1, L+1):\n",
    "        v = np.corrcoef(s[:-lag], s[lag:])[0,1] if len(s) - lag > 1 else np.nan\n",
    "        acf_vals.append(v)\n",
    "    acf_vals = np.array(acf_vals, dtype=float)\n",
    "    thr = 0.25\n",
    "    peaks = [i for i in range(1, len(acf_vals)) if not np.isnan(acf_vals[i]) and acf_vals[i] > thr]\n",
    "    return peaks[0] if peaks else None\n",
    "\n",
    "def adf_kpss_tests(series: pd.Series, alpha: float = 0.05) -> dict:\n",
    "    res = {}\n",
    "    x = series.dropna().values\n",
    "    if len(x) < 20:\n",
    "        return {\"error\": \"Serie demasiado corta para ADF/KPSS\"}\n",
    "    try:\n",
    "        adf_stat, adf_p, _, _, adf_crit, _ = adfuller(series.dropna(), autolag=\"AIC\")\n",
    "        res[\"adf_stat\"] = float(adf_stat); res[\"adf_p\"] = float(adf_p); res[\"adf_stationary_at_alpha\"] = bool(adf_p < alpha)\n",
    "        res[\"adf_crit\"] = {k: float(v) for k, v in adf_crit.items()}\n",
    "    except Exception as e:\n",
    "        res[\"adf_error\"] = str(e)\n",
    "    try:\n",
    "        kpss_stat, kpss_p, _, kpss_crit = kpss(series.dropna(), regression=\"c\", nlags=\"auto\")\n",
    "        res[\"kpss_stat\"] = float(kpss_stat); res[\"kpss_p\"] = float(kpss_p); res[\"kpss_stationary_at_alpha\"] = bool(kpss_p > alpha)\n",
    "        res[\"kpss_crit\"] = {k: float(v) for k, v in kpss_crit.items()}\n",
    "    except Exception as e:\n",
    "        res[\"kpss_error\"] = str(e)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8696a",
   "metadata": {},
   "source": [
    "## 1) Carga y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef697e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(FILE_PATH)\n",
    "assert path.exists(), f\"No se encontró el archivo: {path}\"\n",
    "\n",
    "read_kwargs = {}\n",
    "if CSV_SEP is None:\n",
    "    read_kwargs.update(dict(sep=None, engine=\"python\"))\n",
    "else:\n",
    "    read_kwargs.update(dict(sep=CSV_SEP))\n",
    "\n",
    "df = pd.read_csv(path, **read_kwargs)\n",
    "if SAMPLE_FOR_PLOTS is not None and len(df) > SAMPLE_FOR_PLOTS:\n",
    "    df_sample = df.sample(SAMPLE_FOR_PLOTS, random_state=42).copy()\n",
    "else:\n",
    "    df_sample = df.copy()\n",
    "\n",
    "print(\"Dimensiones:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Parseo de fecha (si existe)\n",
    "date_col = None\n",
    "for cand in [\"Fecha\", \"fecha\", \"DATE\", \"Date\", \"timestamp\", \"time\"]:\n",
    "    if cand in df_sample.columns:\n",
    "        date_col = cand; break\n",
    "\n",
    "if date_col is not None:\n",
    "    df_sample[date_col] = pd.to_datetime(df_sample[date_col], errors=\"coerce\", dayfirst=True, infer_datetime_format=True)\n",
    "    df_sample = df_sample.sort_values(date_col).set_index(date_col)\n",
    "\n",
    "num_cols = df_sample.select_dtypes(include=[float, int]).columns.tolist()\n",
    "cat_cols = [c for c in df_sample.columns if c not in num_cols]\n",
    "print(\"Numéricas:\", num_cols)\n",
    "print(\"Categóricas:\", cat_cols)\n",
    "\n",
    "# Reporte de nulos\n",
    "print(\"\\nNulos por columna:\")\n",
    "print(df_sample.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecb7d4",
   "metadata": {},
   "source": [
    "## 2) Resumen de normalidad (todas las numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6679fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for c in num_cols:\n",
    "    info = describe_normality(df_sample[c].astype(float))\n",
    "    info[\"variable\"] = c\n",
    "    rows.append(info)\n",
    "normality_df = pd.DataFrame(rows).set_index(\"variable\")\n",
    "display(normality_df)\n",
    "# Guardar a CSV\n",
    "out_dir = Path(\"/mnt/data/outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "normality_df.to_csv(out_dir / \"normalidad_variables.csv\")\n",
    "print(\"Guardado:\", out_dir / \"normalidad_variables.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef763b",
   "metadata": {},
   "source": [
    "## 3) Gráficos por variable numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009065df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in num_cols:\n",
    "    s = df_sample[c].dropna().astype(float)\n",
    "    if s.empty:\n",
    "        continue\n",
    "    # Histograma\n",
    "    plt.figure()\n",
    "    s.plot(kind=\"hist\", bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "    plt.title(f\"Histograma - {c}\")\n",
    "    plt.xlabel(c); plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "    # Boxplot\n",
    "    plt.figure()\n",
    "    plt.boxplot(s.values, vert=True, labels=[c])\n",
    "    plt.title(f\"Boxplot - {c}\")\n",
    "    plt.show()\n",
    "    # QQ-plot\n",
    "    plt.figure()\n",
    "    qqplot(s, line='s')\n",
    "    plt.title(f\"QQ-plot vs Normal - {c}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a2dc0",
   "metadata": {},
   "source": [
    "## 4) Series temporales y estacionalidad por variable numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa63c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if isinstance(df_sample.index, pd.DatetimeIndex):\n",
    "    for c in num_cols:\n",
    "        s = df_sample[c].dropna().astype(float)\n",
    "        if len(s) < 50:\n",
    "            continue\n",
    "        # Serie temporal\n",
    "        plt.figure()\n",
    "        s.plot()\n",
    "        plt.title(f\"Serie temporal - {c}\")\n",
    "        plt.xlabel(\"Fecha\"); plt.ylabel(c)\n",
    "        plt.show()\n",
    "\n",
    "        # ADF / KPSS\n",
    "        print(f\"Pruebas de estacionariedad - {c}\")\n",
    "        tests = adf_kpss_tests(s)\n",
    "        for k, v in tests.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "\n",
    "        # ACF / PACF\n",
    "        plt.figure()\n",
    "        plot_acf(s, lags=40)\n",
    "        plt.title(f\"ACF - {c}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plot_pacf(s, lags=40, method=\"ywm\")\n",
    "        plt.title(f\"PACF - {c}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Descomposición\n",
    "        period = infer_seasonal_period(s)\n",
    "        print(f\"Periodo estacional inferido ({c}):\", period)\n",
    "        if period is not None and period >= 2:\n",
    "            try:\n",
    "                res = seasonal_decompose(s.dropna(), period=period, model=\"additive\", extrapolate_trend=\"freq\")\n",
    "                plt.figure(); res.observed.plot(); plt.title(f\"Descomposición Observado - {c}\"); plt.show()\n",
    "                plt.figure(); res.trend.plot();    plt.title(f\"Descomposición Tendencia - {c}\"); plt.show()\n",
    "                plt.figure(); res.seasonal.plot();  plt.title(f\"Descomposición Estacionalidad - {c}\"); plt.show()\n",
    "                plt.figure(); res.resid.plot();     plt.title(f\"Descomposición Residual - {c}\"); plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error en descomposición para {c}:\", e)\n",
    "else:\n",
    "    print(\"El índice no es datetime; no se generan gráficos temporales.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a68c",
   "metadata": {},
   "source": [
    "## 5) Variables categóricas — vistas rápidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in cat_cols:\n",
    "    vc = df_sample[c].value_counts(dropna=False).head(20)\n",
    "    print(f\"Top categorías en {c}:\")\n",
    "    display(vc.to_frame(name=\"conteo\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ca0d7",
   "metadata": {},
   "source": [
    "## 6) Correlación numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_df = df_sample[num_cols].dropna(how=\"all\")\n",
    "if num_df.shape[1] >= 2:\n",
    "    corr = num_df.corr(numeric_only=True)\n",
    "    print(\"Matriz de correlación:\")\n",
    "    display(corr)\n",
    "    corr.to_csv(\"/mnt/data/outputs/correlacion_numericas.csv\")\n",
    "    print(\"Guardado:\", \"/mnt/data/outputs/correlacion_numericas.csv\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(corr.values, aspect=\"auto\")\n",
    "    plt.xticks(range(corr.shape[1]), corr.columns, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(corr.shape[0]), corr.index)\n",
    "    plt.title(\"Mapa de calor de correlación\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay suficientes columnas numéricas para correlación.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b87f8",
   "metadata": {},
   "source": [
    "## 7) Análisis por Cliente (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if BY_CLIENT and \"Cliente\" in df.columns:\n",
    "    base = df.copy()\n",
    "    if date_col is not None and date_col in base.columns:\n",
    "        base[date_col] = pd.to_datetime(base[date_col], errors=\"coerce\", dayfirst=True, infer_datetime_format=True)\n",
    "        base = base.dropna(subset=[date_col])\n",
    "    if date_col is not None:\n",
    "        base = base.sort_values(date_col)\n",
    "    # Top N por volumen de datos\n",
    "    top_clients = base[\"Cliente\"].value_counts().head(CLIENTE_TOP_N).index.tolist()\n",
    "    print(\"Clientes analizados:\", top_clients)\n",
    "\n",
    "    for cli in top_clients:\n",
    "        sub = base[base[\"Cliente\"] == cli].copy()\n",
    "        if date_col is not None:\n",
    "            sub = sub.set_index(date_col)\n",
    "        # Asegurar tipo numérico\n",
    "        for c in [\"Volumen\", \"Temperatura\", \"Presion\"]:\n",
    "            if c in sub.columns:\n",
    "                sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "\n",
    "        print(f\"\\n=== Cliente: {cli} | Observaciones: {len(sub)} ===\")\n",
    "        if len(sub) < 50 or not isinstance(sub.index, pd.DatetimeIndex):\n",
    "            print(\"Insuficiente para análisis temporal.\")\n",
    "            continue\n",
    "\n",
    "        s = sub[\"Volumen\"].dropna().astype(float)\n",
    "        # % de ceros\n",
    "        zero_ratio = (s == 0).mean()\n",
    "        print(f\"Proporción de ceros en Volumen: {zero_ratio:.3%}\")\n",
    "\n",
    "        # Serie y ACF/PACF\n",
    "        plt.figure(); s.plot(); plt.title(f\"Serie Volumen - {cli}\"); plt.xlabel(\"Fecha\"); plt.ylabel(\"Volumen\"); plt.show()\n",
    "        plt.figure(); plot_acf(s, lags=40); plt.title(f\"ACF Volumen - {cli}\"); plt.show()\n",
    "        plt.figure(); plot_pacf(s, lags=40, method=\"ywm\"); plt.title(f\"PACF Volumen - {cli}\"); plt.show()\n",
    "\n",
    "        # Estacionalidad por hora del día / día de semana\n",
    "        sub[\"hora\"] = sub.index.hour\n",
    "        sub[\"dow\"] = sub.index.dayofweek  # 0=Lunes\n",
    "        grp_hod = sub.groupby(\"hora\")[\"Volumen\"].median()\n",
    "        grp_dow = sub.groupby(\"dow\")[\"Volumen\"].median()\n",
    "\n",
    "        plt.figure(); grp_hod.plot(); plt.title(f\"Mediana Volumen por Hora del día - {cli}\"); plt.xlabel(\"Hora\"); plt.ylabel(\"Mediana Volumen\"); plt.show()\n",
    "        plt.figure(); grp_dow.plot(); plt.title(f\"Mediana Volumen por Día de semana - {cli}\"); plt.xlabel(\"Día (0=L)\"); plt.ylabel(\"Mediana Volumen\"); plt.show()\n",
    "\n",
    "        # Estacionariedad\n",
    "        tests = adf_kpss_tests(s)\n",
    "        print(\"ADF/KPSS:\", tests)\n",
    "\n",
    "        # Periodo estacional\n",
    "        per = infer_seasonal_period(s)\n",
    "        print(\"Periodo estacional inferido:\", per)\n",
    "else:\n",
    "    print(\"BY_CLIENT=False o no existe la columna 'Cliente'.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
